<center>
<p align="center" style="font-size:22px">
<a href="https://data-ethics-and-society.github.io/data-ethics-and-society-reading-group">Home</a> 
- <a href="https://data-ethics-and-society.github.io/data-ethics-and-society-reading-group/SESSIONS.html">Sessions</a> 
- <a href="https://data-ethics-and-society.github.io/data-ethics-and-society-reading-group/Guides/guides.html">Guides</a> 
- <a href="https://data-ethics-and-society.github.io/data-ethics-and-society-reading-group/code-of-conduct.html">Code of Conduct</a> 
- <a href="https://data-ethics-and-society.github.io/data-ethics-and-society-reading-group/READING-LIST.html">Reading List</a>
</p>
</center>

# Data Ethics & Society Reading Group 24-08-21 [12:30 - 13:30 GMT](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Data+Science%3A+Ethics+%26+Society+Reading+Group+24-08-2&iso=20210824T1230&p1=136&ah=1)

## Meeting info

### Description

You're welcome to join us for our next Data Ethics & Society Reading Group on Tuesday the 24th August 2021 at [12:30 - 13:30 GMT](https://www.timeanddate.com/worldclock/fixedtime.html?msg=Data+Science%3A+Ethics+%26+Society+Reading+Group+24-08-2&iso=20210824T1230&p1=136&ah=1).

Following our successful event looking at the first three chapters (Earth, Labor and Data), this time we're going to discuss the **final chapters** (Classification, Affect, State & Power) of [Atlas of AI](https://yalebooks.yale.edu/book/9780300209570/atlas-ai) by Kate Crawford.

Atlas of AI presents AI as a technology of extraction: from the minerals drawn from the earth, to the labour pulled from low-wage information workers, to the data taken from every action and expression.

This book can be purchased in the UK from [Blackwell's](https://blackwells.co.uk/bookshop/product/Atlas-of-AI-by-Kate-Crawford-author/9780300209570), [AbeBooks](https://www.abebooks.co.uk/9780300209570/Atlas-Power-Politics-Planetary-Costs-0300209576/plp), [Amazon](https://www.amazon.co.uk/Atlas-AI-Kate-Crawford/dp/0300209576/ref=sr_1_1) (kindle or hardback), or an independent retailer.

#### **You are very welcome to attend if you haven't read any of the book. You are also welcome if you didn't attend the first event!**

We have put together some material related to some of the concepts in the book below.

- [Kate Crawford on “Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence”](https://www.youtube.com/watch?v=KcefG-0InLE), *Kate Crawford*, (video, 48 mins).
Crawford discusses the book in this sub one-hour video using content from the book itself. If you don't have time to read the book, or read/watch/listen to the below, **please watch this video**.

- [Excavating AI](https://excavating.ai/), *Kate Crawford & Trevor Paglen*
Contains a lot of similar material to that covered in the 'Classification' chapter.

- [Artificial Intelligence is Misreading Human Emotion](https://www.theatlantic.com/technology/archive/2021/04/artificial-intelligence-misreading-human-emotion/618696/), *Kate Crawford, The Atlantic*.
This article is adapted from the book's 'Affect' chapter.

- [Google’s artificial intelligence ethics won't curb war by algorithm](https://www.wired.co.uk/article/google-project-maven-drone-warfare-artificial-intelligence), *Phoebe Braithwaite, Wired*.
This article explores how Google was involved with the  US Department of Defense's Project Maven, which used AI to target drone strikes.

- [Stop talking about AI ethics. It’s time to talk about power](https://www.technologyreview.com/2021/04/23/1023549/kate-crawford-atlas-of-ai-review/), *Karen Hao, MIT Technology Review*.
This is a review article for the book, which summarises everything neatly.

Thank you to Harriet for suggesting this week's content, and to all those who suggested content, which we we look forward to sharing at future events.

### Discussion points

There will be time to talk about whatever we like, relating to the paper, but here are some specific questions to think about while you're reading.

- Should AI be used for emotion detection?
- How do we handle individual interpretations/biases when classifying? (e.g. words in WordNet, images in ImageNet)
- Is it fair to keep building systems based on historic data?
- Could AI use in projects like Project Maven ever be truly ethical?

---

<!--

## Meeting notes

### Who came
Number of people: 9

-->
